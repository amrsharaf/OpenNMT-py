{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onmt\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import torch.optim as optimizer\n",
    "from torch import cuda\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from onmt.modules.discriminator import Discriminator\n",
    "from onmt.modules.gradient_reversal import ReverseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Enviroment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Namespace(adapt=True, batch_size=64, brnn=False, brnn_merge='concat', curriculum=False, data='data/demo-train.pt', dropout=0.3, epochs=100, extra_shuffle=False, gpus=[1], input_feed=1, layers=2, learning_rate=.01, learning_rate_decay=0.5, log_interval=50, max_generator_batches=32, max_grad_norm=5, optim='sgd', param_init=0.1, pre_word_vecs_dec=None, pre_word_vecs_enc=None, rnn_size=500, save_model='model', start_decay_at=8, start_epoch=1, train_from='', train_from_state_dict='', word_vec_size=500)\n",
    "\n",
    "opt.cuda = len(opt.gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup up the cuda Eviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.set_device(opt.gpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 'data/demo-train.pt'\n",
      " * vocabulary size. source = 24999; target = 35820\n",
      " * number of training sentences. 10000\n",
      " * maximum batch size. 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data from '%s'\" % opt.data)\n",
    "\n",
    "dataset = torch.load(opt.data)\n",
    "\n",
    "# type(dataset) = <type 'dict'>\n",
    "trainData = onmt.Dataset(dataset['train']['src'],\n",
    "                         dataset['train']['tgt'], opt.batch_size, opt.cuda)\n",
    "validData = onmt.Dataset(dataset['valid']['src'],\n",
    "                         dataset['valid']['tgt'], opt.batch_size, opt.cuda)\n",
    "\n",
    "domain_train = None\n",
    "domain_valid = None\n",
    "if opt.adapt:\n",
    "    assert('domain_train' in dataset)\n",
    "    assert('domain_valid' in dataset)\n",
    "    domain_train = onmt.Dataset(dataset['domain_train']['src'], None,\n",
    "                              opt.batch_size, opt.cuda)\n",
    "    domain_valid = onmt.Dataset(dataset['domain_valid']['src'], None,\n",
    "                              opt.batch_size, opt.cuda)\n",
    "\n",
    "\n",
    "dicts = dataset['dicts']\n",
    "print(' * vocabulary size. source = %d; target = %d' %\n",
    "      (dicts['src'].size(), dicts['tgt'].size()))\n",
    "print(' * number of training sentences. %d' %\n",
    "      len(dataset['train']['src']))\n",
    "print(' * maximum batch size. %d' % opt.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Len: 1\n",
      "--> Src Sentence: .\n",
      "--> Tgt Sentence: Aerobic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lookup_src(x):\n",
    "    return dicts['src'].idxToLabel[x]\n",
    "\n",
    "def lookup_tgt(x):\n",
    "    return dicts['tgt'].idxToLabel[x]\n",
    "\n",
    "for a in trainData.src:\n",
    "    a_list = a.numpy().tolist()\n",
    "    print \"--> Len: \" + str(len(a_list))\n",
    "    print \"--> Src Sentence: \" + str(\" \".join(map(lookup_src, a_list)))\n",
    "    print \"--> Tgt Sentence: \" + str(\" \".join(map(lookup_tgt, a_list))) + \"\\n\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "\n",
    "encoder = onmt.DomainModels.Encoder(opt, dicts['src'])\n",
    "decoder = onmt.DomainModels.Decoder(opt, dicts['tgt'])\n",
    "\n",
    "generator = nn.Sequential(\n",
    "        nn.Linear(opt.rnn_size, dicts['tgt'].size()),\n",
    "        nn.LogSoftmax())\n",
    "\n",
    "if opt.adapt:\n",
    "    discriminator = Discriminator(opt.word_vec_size  * opt.layers)\n",
    "    gradient_reversal = ReverseLayer()\n",
    "    \n",
    "model = onmt.DomainModels.NMTModel(encoder, decoder, discriminator)\n",
    "\n",
    "if len(opt.gpus) >= 1:\n",
    "    model.cuda()\n",
    "    generator.cuda()\n",
    "else:\n",
    "    model.cpu()\n",
    "    generator.cpu()\n",
    "\n",
    "if len(opt.gpus) > 1:\n",
    "    model = nn.DataParallel(model, device_ids=opt.gpus, dim=1)\n",
    "    generator = nn.DataParallel(generator, device_ids=opt.gpus, dim=0)\n",
    "\n",
    "model.generator = generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoryEfficientLoss(outputs, targets, generator, crit, eval=False):\n",
    "    # compute generations one piece at a time\n",
    "    num_correct, loss = 0, 0\n",
    "    outputs = Variable(outputs.data, requires_grad=(not eval), volatile=eval)\n",
    "\n",
    "    batch_size = outputs.size(1)\n",
    "    outputs_split = torch.split(outputs, opt.max_generator_batches)\n",
    "    targets_split = torch.split(targets, opt.max_generator_batches)\n",
    "    for i, (out_t, targ_t) in enumerate(zip(outputs_split, targets_split)):\n",
    "        out_t = out_t.view(-1, out_t.size(2))\n",
    "        scores_t = generator(out_t)\n",
    "        loss_t = crit(scores_t, targ_t.view(-1))\n",
    "        pred_t = scores_t.max(1)[1]\n",
    "        num_correct_t = pred_t.data.eq(targ_t.data).masked_select(targ_t.ne(onmt.Constants.PAD).data).sum()\n",
    "        num_correct += num_correct_t\n",
    "        loss += loss_t.data[0]\n",
    "        if not eval:\n",
    "            loss_t.div(batch_size).backward()\n",
    "\n",
    "    grad_output = None if outputs.grad is None else outputs.grad.data\n",
    "    return loss, grad_output, num_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, criterion, data):\n",
    "    total_loss = 0\n",
    "    total_words = 0\n",
    "    total_num_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "    for i in range(len(data)):\n",
    "        batch = data[i][:-1] # exclude original indices\n",
    "        outputs = model(batch)\n",
    "        targets = batch[1][1:]  # exclude <s> from targets\n",
    "        loss, _, num_correct = memoryEfficientLoss(\n",
    "                outputs, targets, model.generator, criterion, eval=True)\n",
    "        total_loss += loss\n",
    "        total_num_correct += num_correct\n",
    "        total_words += targets.data.ne(onmt.Constants.PAD).sum()\n",
    "\n",
    "    model.train()\n",
    "    return float(total_loss) / float(total_words),\\\n",
    "           float(total_num_correct) / float(total_words)\n",
    "\n",
    "def domain_eval(model, data_old, data_new):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "    total_num_discrim_correct, total_num_discrim_elements = 0, 0\n",
    "    for i in range(min(len(data_new),len(data_old))):\n",
    "        batch_old = data_old[i][:-1] # exclude original indices\n",
    "        batch_new = data_new[i][:-1]\n",
    "        \n",
    "        _, old_domain, new_domain = model(batch_old, domain_batch=batch_new)  \n",
    "        \n",
    "        tgts = Variable(torch.FloatTensor(len(old_domain) + len(new_domain),), requires_grad=False) \n",
    "            \n",
    "        if opt.cuda:\n",
    "            tgts = tgts.cuda()\n",
    "\n",
    "        tgts[:] = 0.0\n",
    "        tgts[:len(old_domain)] = 1.0\n",
    "        discrim_correct, num_discrim_elements = get_accuracy(torch.cat([old_domain, new_domain]).data.squeeze(), tgts.data)\n",
    "        \n",
    "        # Discriminator counts\n",
    "        total_num_discrim_correct += discrim_correct\n",
    "        total_num_discrim_elements += num_discrim_elements\n",
    "        \n",
    "    return float(total_num_discrim_correct) / float(total_num_discrim_elements)\n",
    "\n",
    "def get_accuracy(prediction, truth):\n",
    "    assert(prediction.nelement() == truth.nelement())\n",
    "    prediction[prediction < 0.5]  = 0.0\n",
    "    prediction[prediction >= 0.5] = 1.0\n",
    "    #accuracy = (100.0 * prediction.eq(truth).sum()) / float(prediction.nelement())\n",
    "    return prediction.eq(truth).sum(), float(prediction.nelement())\n",
    "    #return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMTCriterion(vocabSize):\n",
    "    weight = torch.ones(vocabSize)\n",
    "    weight[onmt.Constants.PAD] = 0\n",
    "    crit = nn.NLLLoss(weight, size_average=False)\n",
    "    if opt.cuda:\n",
    "        crit.cuda()\n",
    "    return crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences (batch,domain_batch):\n",
    "    for old_sentence_src, old_sentence_tgt, new_sentence in zip(batch[0],batch[1],domain_batch) :\n",
    "        old_sentence_src = [dataset['dicts']['src'].idxToLabel[x] for x in old_sentence_src.data]\n",
    "        old_sentence_src = \" \".join(old_sentence_src)\n",
    "        print \"old sentence src: \", old_sentence_src \n",
    "                    \n",
    "        old_sentence_tgt = [dataset['dicts']['tgt'].idxToLabel[x] for x in old_sentence_tgt.data]\n",
    "        old_sentence_tgt = \" \".join(old_sentence_tgt)\n",
    "        print \"old sentence tgt: \", old_sentence_tgt \n",
    "\n",
    "        new_sentence = [dataset['dicts']['src'].idxToLabel[x] for x in new_sentence.data]\n",
    "        new_sentence = \" \".join(new_sentence)\n",
    "        print \"\\nnew sentence: \", new_sentence\n",
    "                    \n",
    "        print \"-------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, trainData, validData, domain_train, domain_valid, dataset, optim):\n",
    "    print(model)\n",
    "    model.train()\n",
    "\n",
    "    # define criterion of each GPU\n",
    "    criterion = NMTCriterion(dataset['dicts']['tgt'].size())\n",
    "\n",
    "    start_time = time.time()\n",
    "    def trainEpoch(epoch):\n",
    "        \n",
    "        if opt.extra_shuffle and epoch > opt.curriculum:\n",
    "            trainData.shuffle()\n",
    "\n",
    "        # shuffle mini batch order\n",
    "        batchOrder = torch.randperm(len(trainData))\n",
    "        \n",
    "        discriminator_criterion = None\n",
    "        if opt.adapt:\n",
    "            batchOrderAdapt = torch.randperm(len(domain_train))\n",
    "            discriminator_criterion = nn.BCELoss()\n",
    "\n",
    "        total_num_discrim_correct, total_num_discrim_elements = 0, 0\n",
    "        total_loss, total_words, total_num_correct = 0, 0, 0\n",
    "        report_loss, report_tgt_words, report_src_words, report_num_correct = 0, 0, 0, 0\n",
    "        start = time.time()\n",
    "        for i in range(len(trainData)):\n",
    "\n",
    "            batchIdx = batchOrder[i] if epoch > opt.curriculum else i   \n",
    "            batch = trainData[batchIdx][:-1] # exclude original indices\n",
    "            \n",
    "            if debug:\n",
    "                print \"trainData batch size: \", trainData.batchSize\n",
    "                print \"batch len : \", len(batch)\n",
    "                \n",
    "                print \"\\n\\nbacth size: \", (len(batch[0][1]))\n",
    "                print \"other ---->: \", batch[0][1]\n",
    "                print \"batchIdx: \",batchIdx\n",
    "\n",
    "            model.zero_grad()\n",
    "            if opt.adapt:\n",
    "                batchIdxAdapt = batchOrderAdapt[i] if epoch >= opt.curriculum else i\n",
    "                batch_len = len(batch[0][1])\n",
    "                domain_batch = domain_train[batchIdxAdapt][:-1]\n",
    "                \n",
    "                if debug:\n",
    "                    print \"domain_train batch size: \", domain_train.batchSize\n",
    "                    print \"domain_batch[0] type: \", type(domain_batch[0])\n",
    "                    print \"domain_batch[0][0] type: \", type(domain_batch[0][0]), '\\n'\n",
    "\n",
    "                outputs, old_domain, new_domain = model(batch, domain_batch=domain_batch)       \n",
    "                discriminator_targets = Variable(torch.FloatTensor(len(old_domain) + len(new_domain),), requires_grad=False)\n",
    "\n",
    "                if opt.cuda:\n",
    "                    discriminator_targets = discriminator_targets.cuda()\n",
    "                \n",
    "                discriminator_targets[:] = 0.0\n",
    "                discriminator_targets[:len(old_domain)] = 1.0\n",
    "                discrim_correct, num_discrim_elements = get_accuracy(torch.cat([old_domain, new_domain]).data.squeeze(), discriminator_targets.data)\n",
    "                \n",
    "                discriminator_loss = discriminator_criterion(torch.cat([old_domain, new_domain]), discriminator_targets)\n",
    "            else:\n",
    "                outputs = model(batch)\n",
    "\n",
    "            targets = batch[1][1:]  # exclude <s> from targets\n",
    "            loss, gradOutput, num_correct = memoryEfficientLoss(\n",
    "                    outputs, targets, model.generator, criterion)\n",
    "\n",
    "            # We do the domain adaptation backward call here\n",
    "            if opt.adapt:\n",
    "                outputs.backward(gradOutput, retain_variables=True)\n",
    "                model.zero_grad()\n",
    "                discriminator_loss.backward()\n",
    "            else:\n",
    "                outputs.backward(gradOutput)\n",
    "    \n",
    "\n",
    "            # update the parameters\n",
    "            optim.step()\n",
    "\n",
    "            num_words = targets.data.ne(onmt.Constants.PAD).sum()\n",
    "            report_loss += loss\n",
    "            report_num_correct += num_correct\n",
    "            report_tgt_words += num_words\n",
    "            report_src_words += sum(batch[0][1])\n",
    "            total_loss += loss\n",
    "            total_num_correct += num_correct\n",
    "            total_words += num_words\n",
    "            \n",
    "            # Discriminator counts\n",
    "            total_num_discrim_correct += discrim_correct\n",
    "            total_num_discrim_elements += num_discrim_elements\n",
    "            \n",
    "            if i % opt.log_interval == -1 % opt.log_interval:\n",
    "                print(\"Epoch %2d, %5d/%5d; acc: %6.2f; ppl: %6.2f; %3.0f src tok/s; %3.0f tgt tok/s; %6.0f s elapsed\" %\n",
    "                      (epoch, i+1, len(trainData),\n",
    "                      report_num_correct / report_tgt_words * 100,\n",
    "                      math.exp(report_loss / report_tgt_words),\n",
    "                      report_src_words/(time.time()-start),\n",
    "                      report_tgt_words/(time.time()-start),\n",
    "                      time.time()-start_time))\n",
    "                \n",
    "                print \"discrim_correct: \", discrim_correct\n",
    "                print \"num_discrim_elements: \", num_discrim_elements, '\\n'\n",
    "\n",
    "                report_loss = report_tgt_words = report_src_words = report_num_correct = 0\n",
    "                start = time.time()\n",
    "\n",
    "        return float(total_loss) / float(total_words),\\\n",
    "               float(total_num_correct) / float(total_words),\\\n",
    "               float(total_num_discrim_correct) / float(total_num_discrim_elements)\n",
    "\n",
    "    for epoch in range(opt.start_epoch, opt.epochs + 1):\n",
    "        print('')\n",
    "\n",
    "        #  (1) train for one epoch on the training set\n",
    "        train_loss, train_acc, train_discrim_acc = trainEpoch(epoch)\n",
    "        print('Train perplexity: %g' % math.exp(min(train_loss, 100)))\n",
    "        print('Train accuracy: %g' % (train_acc*100))\n",
    "        print('Train discriminator accuracy: %g' % (train_discrim_acc * 100))\n",
    "\n",
    "        #  (2) evaluate on the validation set\n",
    "        valid_loss, valid_acc = eval(model, criterion, validData)\n",
    "        valid_discrim_acc = domain_eval(model, validData, domain_valid)\n",
    "        valid_ppl = math.exp(min(valid_loss, 100))\n",
    "        print('Validation perplexity: %g' % valid_ppl)\n",
    "        print('Validation accuracy: %g' % (valid_acc*100))\n",
    "        print('Validation discriminator accuracy: %g' % (valid_discrim_acc * 100))\n",
    "\n",
    "        \n",
    "        #  (3) update the learning rate\n",
    "        # optim.updateLearningRate(valid_loss, epoch)\n",
    "\n",
    "        model_state_dict = model.module.state_dict() if len(opt.gpus) > 1 else model.state_dict()\n",
    "        model_state_dict = {k: v for k, v in model_state_dict.items() if 'generator' not in k}\n",
    "        generator_state_dict = model.generator.module.state_dict() if len(opt.gpus) > 1 else model.generator.state_dict()\n",
    "        #  (4) drop a checkpoint\n",
    "        checkpoint = {\n",
    "            'model': model_state_dict,\n",
    "            'generator': generator_state_dict,\n",
    "            'dicts': dataset['dicts'],\n",
    "            'opt': opt,\n",
    "            'epoch': epoch,\n",
    "            'optim': optim\n",
    "        }\n",
    "        torch.save(checkpoint,\n",
    "                   '%s_acc_%.2f_ppl_%.2f_e%d.pt' % (opt.save_model, 100*valid_acc, valid_ppl, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* number of parameters: 74130322\n",
      "NMTModel (\n",
      "  (encoder): Encoder (\n",
      "    (word_lut): Embedding(24999, 500, padding_idx=0)\n",
      "    (rnn): LSTM(500, 500, num_layers=2, dropout=0.3)\n",
      "  )\n",
      "  (decoder): Decoder (\n",
      "    (word_lut): Embedding(35820, 500, padding_idx=0)\n",
      "    (rnn): StackedLSTM (\n",
      "      (dropout): Dropout (p = 0.3)\n",
      "      (layers): ModuleList (\n",
      "        (0): LSTMCell(1000, 500)\n",
      "        (1): LSTMCell(500, 500)\n",
      "      )\n",
      "    )\n",
      "    (attn): GlobalAttention (\n",
      "      (linear_in): Linear (500 -> 500)\n",
      "      (sm): Softmax ()\n",
      "      (linear_out): Linear (1000 -> 500)\n",
      "      (tanh): Tanh ()\n",
      "    )\n",
      "    (dropout): Dropout (p = 0.3)\n",
      "  )\n",
      "  (discriminator): Discriminator (\n",
      "    (lin1): Linear (1000 -> 1)\n",
      "    (lin2): Linear (4000 -> 4000)\n",
      "    (lin3): Linear (4000 -> 1)\n",
      "  )\n",
      "  (generator): Sequential (\n",
      "    (0): Linear (500 -> 35820)\n",
      "    (1): LogSoftmax ()\n",
      "  )\n",
      ")\n",
      "\n",
      "Epoch  1,    50/  157; acc:   0.00; ppl: 37547.76; 4131 src tok/s; 4079 tgt tok/s;     18 s elapsed\n",
      "discrim_correct:  68\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  1,   100/  157; acc:   0.00; ppl: 37556.68; 3990 src tok/s; 3991 tgt tok/s;     35 s elapsed\n",
      "discrim_correct:  99\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  1,   150/  157; acc:   0.00; ppl: 37550.28; 4034 src tok/s; 4038 tgt tok/s;     53 s elapsed\n",
      "discrim_correct:  30\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37555.2\n",
      "Train accuracy: 0.000892861\n",
      "Train discriminator accuracy: 58.9685\n",
      "Validation perplexity: 35280.6\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 76.9258\n",
      "\n",
      "Epoch  2,    50/  157; acc:   0.00; ppl: 37313.43; 4217 src tok/s; 4206 tgt tok/s;     79 s elapsed\n",
      "discrim_correct:  50\n",
      "num_discrim_elements:  80.0 \n",
      "\n",
      "Epoch  2,   100/  157; acc:   0.00; ppl: 37278.63; 4147 src tok/s; 4161 tgt tok/s;     95 s elapsed\n",
      "discrim_correct:  0\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  2,   150/  157; acc:   0.00; ppl: 37316.75; 4611 src tok/s; 4583 tgt tok/s;    111 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37305.6\n",
      "Train accuracy: 0.00223215\n",
      "Train discriminator accuracy: 61.9713\n",
      "Validation perplexity: 35143.8\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 84.6464\n",
      "\n",
      "Epoch  3,    50/  157; acc:   0.00; ppl: 37327.99; 4423 src tok/s; 4330 tgt tok/s;    137 s elapsed\n",
      "discrim_correct:  65\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  3,   100/  157; acc:   0.00; ppl: 37309.56; 4584 src tok/s; 4615 tgt tok/s;    152 s elapsed\n",
      "discrim_correct:  128\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  3,   150/  157; acc:   0.00; ppl: 37317.67; 4273 src tok/s; 4256 tgt tok/s;    169 s elapsed\n",
      "discrim_correct:  65\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37319.6\n",
      "Train accuracy: 0.00178572\n",
      "Train discriminator accuracy: 61.9264\n",
      "Validation perplexity: 35099.7\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 84.313\n",
      "\n",
      "Epoch  4,    50/  157; acc:   0.00; ppl: 37373.20; 4459 src tok/s; 4392 tgt tok/s;    195 s elapsed\n",
      "discrim_correct:  128\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  4,   100/  157; acc:   0.00; ppl: 37360.59; 4431 src tok/s; 4354 tgt tok/s;    212 s elapsed\n",
      "discrim_correct:  66\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37353.8\n",
      "Train accuracy: 0.00267858\n",
      "Train discriminator accuracy: 65.2684\n",
      "Validation perplexity: 35077.6\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 85.0851\n",
      "\n",
      "Epoch  5,    50/  157; acc:   0.00; ppl: 37408.09; 4314 src tok/s; 4302 tgt tok/s;    255 s elapsed\n",
      "discrim_correct:  83\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  5,   100/  157; acc:   0.00; ppl: 37393.72; 4152 src tok/s; 4157 tgt tok/s;    272 s elapsed\n",
      "discrim_correct:  95\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  5,   150/  157; acc:   0.00; ppl: 37375.41; 4266 src tok/s; 4218 tgt tok/s;    289 s elapsed\n",
      "discrim_correct:  74\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37389.5\n",
      "Train accuracy: 0.00133929\n",
      "Train discriminator accuracy: 67.8771\n",
      "Validation perplexity: 35116.8\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 84.5587\n",
      "\n",
      "Epoch  6,    50/  157; acc:   0.00; ppl: 37455.79; 4376 src tok/s; 4305 tgt tok/s;    315 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  6,   100/  157; acc:   0.00; ppl: 37391.85; 4053 src tok/s; 4086 tgt tok/s;    332 s elapsed\n",
      "discrim_correct:  104\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  6,   150/  157; acc:   0.00; ppl: 37446.98; 4411 src tok/s; 4387 tgt tok/s;    348 s elapsed\n",
      "discrim_correct:  22\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37428.5\n",
      "Train accuracy: 0.00133929\n",
      "Train discriminator accuracy: 71.3587\n",
      "Validation perplexity: 35282\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 63.2567\n",
      "\n",
      "Epoch  7,    50/  157; acc:   0.00; ppl: 37393.86; 4226 src tok/s; 4219 tgt tok/s;    375 s elapsed\n",
      "discrim_correct:  110\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  7,   100/  157; acc:   0.00; ppl: 37484.35; 3991 src tok/s; 4033 tgt tok/s;    392 s elapsed\n",
      "discrim_correct:  74\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  7,   150/  157; acc:   0.00; ppl: 37502.29; 4349 src tok/s; 4279 tgt tok/s;    408 s elapsed\n",
      "discrim_correct:  98\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37477.6\n",
      "Train accuracy: 0.000446431\n",
      "Train discriminator accuracy: 76.0824\n",
      "Validation perplexity: 35305.9\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 74.5569\n",
      "\n",
      "Epoch  8,    50/  157; acc:   0.00; ppl: 37448.53; 4019 src tok/s; 4050 tgt tok/s;    435 s elapsed\n",
      "discrim_correct:  97\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  8,   100/  157; acc:   0.00; ppl: 37520.38; 4442 src tok/s; 4354 tgt tok/s;    452 s elapsed\n",
      "discrim_correct:  102\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  8,   150/  157; acc:   0.00; ppl: 37476.54; 4072 src tok/s; 4091 tgt tok/s;    468 s elapsed\n",
      "discrim_correct:  97\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37498.7\n",
      "Train accuracy: 0.00178572\n",
      "Train discriminator accuracy: 79.8234\n",
      "Validation perplexity: 35507.9\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 85.436\n",
      "\n",
      "Epoch  9,    50/  157; acc:   0.00; ppl: 37479.19; 4305 src tok/s; 4270 tgt tok/s;    495 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  9,   100/  157; acc:   0.00; ppl: 37539.36; 4225 src tok/s; 4195 tgt tok/s;    512 s elapsed\n",
      "discrim_correct:  99\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch  9,   150/  157; acc:   0.00; ppl: 37545.67; 4069 src tok/s; 4066 tgt tok/s;    529 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37520.9\n",
      "Train accuracy: 0.00267858\n",
      "Train discriminator accuracy: 83.0407\n",
      "Validation perplexity: 35309.5\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 82.3478\n",
      "\n",
      "Epoch 10,    50/  157; acc:   0.00; ppl: 37619.49; 4443 src tok/s; 4342 tgt tok/s;    556 s elapsed\n",
      "discrim_correct:  74\n",
      "num_discrim_elements:  80.0 \n",
      "\n",
      "Epoch 10,   100/  157; acc:   0.00; ppl: 37483.71; 3923 src tok/s; 3967 tgt tok/s;    573 s elapsed\n",
      "discrim_correct:  113\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 10,   150/  157; acc:   0.00; ppl: 37500.48; 4267 src tok/s; 4238 tgt tok/s;    590 s elapsed\n",
      "discrim_correct:  114\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37523.5\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 84.6419\n",
      "Validation perplexity: 35368.8\n",
      "Validation accuracy: 0\n",
      "Validation discriminator accuracy: 76.1186\n",
      "\n",
      "Epoch 11,    50/  157; acc:   0.00; ppl: 37442.34; 4120 src tok/s; 4098 tgt tok/s;    616 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 11,   100/  157; acc:   0.00; ppl: 37594.05; 4268 src tok/s; 4235 tgt tok/s;    634 s elapsed\n",
      "discrim_correct:  119\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 11,   150/  157; acc:   0.00; ppl: 37644.37; 4158 src tok/s; 4146 tgt tok/s;    651 s elapsed\n",
      "discrim_correct:  116\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37559.9\n",
      "Train accuracy: 0.00223215\n",
      "Train discriminator accuracy: 87.2556\n",
      "Validation perplexity: 35448.3\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 81.1195\n",
      "\n",
      "Epoch 12,    50/  157; acc:   0.00; ppl: 37604.69; 4214 src tok/s; 4186 tgt tok/s;    678 s elapsed\n",
      "discrim_correct:  108\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 12,   100/  157; acc:   0.00; ppl: 37579.09; 4444 src tok/s; 4364 tgt tok/s;    695 s elapsed\n",
      "discrim_correct:  119\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 12,   150/  157; acc:   0.00; ppl: 37513.33; 3873 src tok/s; 3921 tgt tok/s;    712 s elapsed\n",
      "discrim_correct:  112\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37569.6\n",
      "Train accuracy: 0.00446431\n",
      "Train discriminator accuracy: 87.2207\n",
      "Validation perplexity: 35540.4\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 87.8751\n",
      "\n",
      "Epoch 13,    50/  157; acc:   0.00; ppl: 37512.50; 4196 src tok/s; 4210 tgt tok/s;    738 s elapsed\n",
      "discrim_correct:  104\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 13,   100/  157; acc:   0.00; ppl: 37606.52; 4308 src tok/s; 4259 tgt tok/s;    756 s elapsed\n",
      "discrim_correct:  127\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 13,   150/  157; acc:   0.00; ppl: 37566.35; 4040 src tok/s; 4022 tgt tok/s;    773 s elapsed\n",
      "discrim_correct:  117\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37567.4\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 89.4254\n",
      "Validation perplexity: 35708.5\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 90.472\n",
      "\n",
      "Epoch 14,    50/  157; acc:   0.00; ppl: 37625.48; 4336 src tok/s; 4272 tgt tok/s;    799 s elapsed\n",
      "discrim_correct:  105\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 14,   100/  157; acc:   0.00; ppl: 37530.95; 4413 src tok/s; 4374 tgt tok/s;    816 s elapsed\n",
      "discrim_correct:  116\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 14,   150/  157; acc:   0.00; ppl: 37557.32; 4178 src tok/s; 4231 tgt tok/s;    832 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37575.1\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 89.6698\n",
      "Validation perplexity: 35658.7\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 89.9456\n",
      "\n",
      "Epoch 15,    50/  157; acc:   0.00; ppl: 37601.50; 4241 src tok/s; 4226 tgt tok/s;    858 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 15,   100/  157; acc:   0.00; ppl: 37614.40; 4293 src tok/s; 4203 tgt tok/s;    876 s elapsed\n",
      "discrim_correct:  109\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 15,   150/  157; acc:   0.00; ppl: 37501.73; 4063 src tok/s; 4090 tgt tok/s;    893 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37574\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 90.4379\n",
      "Validation perplexity: 35623.2\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 89.349\n",
      "\n",
      "Epoch 16,    50/  157; acc:   0.00; ppl: 37628.21; 4222 src tok/s; 4173 tgt tok/s;    920 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 16,   100/  157; acc:   0.00; ppl: 37546.24; 4231 src tok/s; 4208 tgt tok/s;    937 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 16,   150/  157; acc:   0.00; ppl: 37553.64; 4078 src tok/s; 4089 tgt tok/s;    954 s elapsed\n",
      "discrim_correct:  116\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37574.8\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 90.9318\n",
      "Validation perplexity: 35723.7\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 90.823\n",
      "\n",
      "Epoch 17,    50/  157; acc:   0.00; ppl: 37558.54; 3864 src tok/s; 3839 tgt tok/s;    982 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 17,   100/  157; acc:   0.00; ppl: 37519.69; 4264 src tok/s; 4239 tgt tok/s;    998 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 17,   150/  157; acc:   0.00; ppl: 37634.25; 4242 src tok/s; 4243 tgt tok/s;   1015 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37566.8\n",
      "Train accuracy: 0.00401788\n",
      "Train discriminator accuracy: 92.0042\n",
      "Validation perplexity: 35678.4\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 90.1386\n",
      "\n",
      "Epoch 18,    50/  157; acc:   0.00; ppl: 37518.44; 3899 src tok/s; 3958 tgt tok/s;   1041 s elapsed\n",
      "discrim_correct:  116\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 18,   100/  157; acc:   0.00; ppl: 37633.69; 4709 src tok/s; 4572 tgt tok/s;   1058 s elapsed\n",
      "discrim_correct:  119\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 18,   150/  157; acc:   0.00; ppl: 37538.55; 4233 src tok/s; 4267 tgt tok/s;   1074 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37564.7\n",
      "Train accuracy: 0.00357144\n",
      "Train discriminator accuracy: 91.8895\n",
      "Validation perplexity: 35506.5\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 82.1548\n",
      "\n",
      "Epoch 19,    50/  157; acc:   0.00; ppl: 37513.61; 4140 src tok/s; 4144 tgt tok/s;   1100 s elapsed\n",
      "discrim_correct:  123\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 19,   100/  157; acc:   0.00; ppl: 37568.90; 4528 src tok/s; 4465 tgt tok/s;   1117 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 19,   150/  157; acc:   0.00; ppl: 37605.21; 4371 src tok/s; 4341 tgt tok/s;   1134 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37556.3\n",
      "Train accuracy: 0.00446431\n",
      "Train discriminator accuracy: 92.3991\n",
      "Validation perplexity: 35668.7\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 90.7528\n",
      "\n",
      "Epoch 20,    50/  157; acc:   0.00; ppl: 37501.31; 4313 src tok/s; 4283 tgt tok/s;   1160 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 20,   100/  157; acc:   0.00; ppl: 37562.69; 4368 src tok/s; 4394 tgt tok/s;   1176 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 20,   150/  157; acc:   0.00; ppl: 37595.51; 4344 src tok/s; 4274 tgt tok/s;   1193 s elapsed\n",
      "discrim_correct:  97\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37546.4\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 92.9868\n",
      "Validation perplexity: 35664\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 89.9105\n",
      "\n",
      "Epoch 21,    50/  157; acc:   0.00; ppl: 37608.34; 4373 src tok/s; 4329 tgt tok/s;   1219 s elapsed\n",
      "discrim_correct:  97\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 21,   100/  157; acc:   0.00; ppl: 37491.15; 4272 src tok/s; 4278 tgt tok/s;   1235 s elapsed\n",
      "discrim_correct:  109\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 21,   150/  157; acc:   0.00; ppl: 37527.06; 4142 src tok/s; 4144 tgt tok/s;   1252 s elapsed\n",
      "discrim_correct:  128\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37557.3\n",
      "Train accuracy: 0.00401788\n",
      "Train discriminator accuracy: 92.9818\n",
      "Validation perplexity: 35728\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 91.6301\n",
      "\n",
      "Epoch 22,    50/  157; acc:   0.00; ppl: 37528.29; 4137 src tok/s; 4137 tgt tok/s;   1278 s elapsed\n",
      "discrim_correct:  106\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 22,   100/  157; acc:   0.00; ppl: 37520.76; 4448 src tok/s; 4392 tgt tok/s;   1294 s elapsed\n",
      "discrim_correct:  116\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 22,   150/  157; acc:   0.00; ppl: 37502.64; 4227 src tok/s; 4244 tgt tok/s;   1311 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37519.7\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 92.8172\n",
      "Validation perplexity: 35599.4\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 89.3666\n",
      "\n",
      "Epoch 23,    50/  157; acc:   0.00; ppl: 37499.21; 4129 src tok/s; 4169 tgt tok/s;   1337 s elapsed\n",
      "discrim_correct:  113\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 23,   100/  157; acc:   0.00; ppl: 37554.11; 4407 src tok/s; 4390 tgt tok/s;   1353 s elapsed\n",
      "discrim_correct:  122\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 23,   150/  157; acc:   0.00; ppl: 37513.11; 4369 src tok/s; 4307 tgt tok/s;   1370 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37525.5\n",
      "Train accuracy: 0.00401788\n",
      "Train discriminator accuracy: 93.6802\n",
      "Validation perplexity: 35643.6\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 90.4545\n",
      "\n",
      "Epoch 24,    50/  157; acc:   0.00; ppl: 37544.96; 4177 src tok/s; 4172 tgt tok/s;   1397 s elapsed\n",
      "discrim_correct:  122\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 24,   100/  157; acc:   0.00; ppl: 37423.28; 4200 src tok/s; 4240 tgt tok/s;   1413 s elapsed\n",
      "discrim_correct:  114\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 24,   150/  157; acc:   0.00; ppl: 37523.28; 4489 src tok/s; 4403 tgt tok/s;   1430 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37501.4\n",
      "Train accuracy: 0.00357144\n",
      "Train discriminator accuracy: 93.321\n",
      "Validation perplexity: 35480.4\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 86.8398\n",
      "\n",
      "Epoch 25,    50/  157; acc:   0.00; ppl: 37510.83; 4278 src tok/s; 4261 tgt tok/s;   1455 s elapsed\n",
      "discrim_correct:  127\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 25,   100/  157; acc:   0.00; ppl: 37510.10; 4122 src tok/s; 4171 tgt tok/s;   1471 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 25,   150/  157; acc:   0.00; ppl: 37541.00; 4567 src tok/s; 4490 tgt tok/s;   1489 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37524.5\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 94.4832\n",
      "Validation perplexity: 35821\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 91.7178\n",
      "\n",
      "Epoch 26,    50/  157; acc:   0.00; ppl: 37558.15; 4323 src tok/s; 4299 tgt tok/s;   1515 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 26,   100/  157; acc:   0.00; ppl: 37422.77; 3943 src tok/s; 4027 tgt tok/s;   1531 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 26,   150/  157; acc:   0.00; ppl: 37548.18; 4510 src tok/s; 4433 tgt tok/s;   1548 s elapsed\n",
      "discrim_correct:  115\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37516.4\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 93.8148\n",
      "Validation perplexity: 35801\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 92.3846\n",
      "\n",
      "Epoch 27,    50/  157; acc:   0.00; ppl: 37538.50; 4478 src tok/s; 4437 tgt tok/s;   1574 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 27,   100/  157; acc:   0.00; ppl: 37403.05; 4311 src tok/s; 4326 tgt tok/s;   1590 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 27,   150/  157; acc:   0.00; ppl: 37574.57; 4474 src tok/s; 4412 tgt tok/s;   1607 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37502.6\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 94.2388\n",
      "Validation perplexity: 35822.6\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 92.0161\n",
      "\n",
      "Epoch 28,    50/  157; acc:   0.00; ppl: 37511.51; 4514 src tok/s; 4455 tgt tok/s;   1632 s elapsed\n",
      "discrim_correct:  109\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 28,   100/  157; acc:   0.00; ppl: 37437.01; 4072 src tok/s; 4134 tgt tok/s;   1648 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 28,   150/  157; acc:   0.00; ppl: 37507.95; 4563 src tok/s; 4512 tgt tok/s;   1665 s elapsed\n",
      "discrim_correct:  115\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37490.8\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 94.8524\n",
      "Validation perplexity: 35857.4\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 92.6478\n",
      "\n",
      "Epoch 29,    50/  157; acc:   0.00; ppl: 37486.63; 4313 src tok/s; 4274 tgt tok/s;   1691 s elapsed\n",
      "discrim_correct:  116\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 29,   100/  157; acc:   0.00; ppl: 37422.60; 4482 src tok/s; 4466 tgt tok/s;   1706 s elapsed\n",
      "discrim_correct:  123\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 29,   150/  157; acc:   0.00; ppl: 37478.05; 4364 src tok/s; 4356 tgt tok/s;   1723 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37470.2\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 94.8075\n",
      "Validation perplexity: 35461.5\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 81.9267\n",
      "\n",
      "Epoch 30,    50/  157; acc:   0.00; ppl: 37448.04; 4177 src tok/s; 4184 tgt tok/s;   1750 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 30,   100/  157; acc:   0.00; ppl: 37448.87; 4297 src tok/s; 4267 tgt tok/s;   1766 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 30,   150/  157; acc:   0.00; ppl: 37440.15; 4535 src tok/s; 4503 tgt tok/s;   1782 s elapsed\n",
      "discrim_correct:  123\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37447.6\n",
      "Train accuracy: 0.00401788\n",
      "Train discriminator accuracy: 94.9122\n",
      "Validation perplexity: 35759.7\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 92.0863\n",
      "\n",
      "Epoch 31,    50/  157; acc:   0.00; ppl: 37469.24; 4228 src tok/s; 4229 tgt tok/s;   1808 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 31,   100/  157; acc:   0.00; ppl: 37423.27; 4486 src tok/s; 4452 tgt tok/s;   1825 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 31,   150/  157; acc:   0.00; ppl: 37457.64; 4471 src tok/s; 4430 tgt tok/s;   1841 s elapsed\n",
      "discrim_correct:  104\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37449.5\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 95.3761\n",
      "Validation perplexity: 35779.8\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 91.8407\n",
      "\n",
      "Epoch 32,    50/  157; acc:   0.00; ppl: 37497.08; 4869 src tok/s; 4699 tgt tok/s;   1867 s elapsed\n",
      "discrim_correct:  119\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 32,   100/  157; acc:   0.00; ppl: 37360.74; 4204 src tok/s; 4217 tgt tok/s;   1883 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 32,   150/  157; acc:   0.00; ppl: 37413.66; 4079 src tok/s; 4185 tgt tok/s;   1899 s elapsed\n",
      "discrim_correct:  115\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37425\n",
      "Train accuracy: 0.00357144\n",
      "Train discriminator accuracy: 95.0269\n",
      "Validation perplexity: 35429.5\n",
      "Validation accuracy: 0.00156099\n",
      "Validation discriminator accuracy: 81.4704\n",
      "\n",
      "Epoch 33,    50/  157; acc:   0.00; ppl: 37435.57; 4223 src tok/s; 4253 tgt tok/s;   1924 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 33,   100/  157; acc:   0.00; ppl: 37356.37; 4455 src tok/s; 4419 tgt tok/s;   1941 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 33,   150/  157; acc:   0.00; ppl: 37435.39; 4507 src tok/s; 4463 tgt tok/s;   1957 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37412.5\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 95.4005\n",
      "Validation perplexity: 35628.9\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 89.8403\n",
      "\n",
      "Epoch 34,    50/  157; acc:   0.00; ppl: 37402.84; 4456 src tok/s; 4418 tgt tok/s;   1983 s elapsed\n",
      "discrim_correct:  122\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 34,   100/  157; acc:   0.00; ppl: 37460.87; 4429 src tok/s; 4334 tgt tok/s;   2000 s elapsed\n",
      "discrim_correct:  122\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 34,   150/  157; acc:   0.00; ppl: 37306.12; 4105 src tok/s; 4205 tgt tok/s;   2016 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37391.4\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 95.5108\n",
      "Validation perplexity: 35683.9\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 90.1562\n",
      "\n",
      "Epoch 35,    50/  157; acc:   0.00; ppl: 37398.83; 4315 src tok/s; 4262 tgt tok/s;   2042 s elapsed\n",
      "discrim_correct:  128\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 35,   100/  157; acc:   0.00; ppl: 37317.22; 4233 src tok/s; 4248 tgt tok/s;   2059 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 36,    50/  157; acc:   0.00; ppl: 37316.89; 4253 src tok/s; 4233 tgt tok/s;   2101 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 36,   100/  157; acc:   0.00; ppl: 37409.84; 4387 src tok/s; 4355 tgt tok/s;   2118 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 36,   150/  157; acc:   0.00; ppl: 37415.55; 4346 src tok/s; 4310 tgt tok/s;   2135 s elapsed\n",
      "discrim_correct:  125\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37374.4\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 95.85\n",
      "Validation perplexity: 35480.4\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 86.0502\n",
      "\n",
      "Epoch 37,    50/  157; acc:   0.00; ppl: 37309.30; 4347 src tok/s; 4320 tgt tok/s;   2160 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 37,   100/  157; acc:   0.00; ppl: 37346.11; 4178 src tok/s; 4200 tgt tok/s;   2177 s elapsed\n",
      "discrim_correct:  123\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 37,   150/  157; acc:   0.00; ppl: 37391.02; 4332 src tok/s; 4268 tgt tok/s;   2194 s elapsed\n",
      "discrim_correct:  124\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37351\n",
      "Train accuracy: 0.00312501\n",
      "Train discriminator accuracy: 96.0096\n",
      "Validation perplexity: 35476.2\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 85.8045\n",
      "\n",
      "Epoch 38,    50/  157; acc:   0.00; ppl: 37381.15; 4267 src tok/s; 4247 tgt tok/s;   2220 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 38,   100/  157; acc:   0.00; ppl: 37338.49; 4245 src tok/s; 4221 tgt tok/s;   2237 s elapsed\n",
      "discrim_correct:  126\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 38,   150/  157; acc:   0.00; ppl: 37368.99; 4453 src tok/s; 4415 tgt tok/s;   2254 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37358.5\n",
      "Train accuracy: 0.00223215\n",
      "Train discriminator accuracy: 96.0295\n",
      "Validation perplexity: 35668.6\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 91.1739\n",
      "\n",
      "Epoch 39,    50/  157; acc:   0.00; ppl: 37256.13; 4186 src tok/s; 4161 tgt tok/s;   2280 s elapsed\n",
      "discrim_correct:  120\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 39,   100/  157; acc:   0.00; ppl: 37311.00; 4356 src tok/s; 4310 tgt tok/s;   2297 s elapsed\n",
      "discrim_correct:  128\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Epoch 39,   150/  157; acc:   0.00; ppl: 37363.05; 4255 src tok/s; 4273 tgt tok/s;   2313 s elapsed\n",
      "discrim_correct:  121\n",
      "num_discrim_elements:  128.0 \n",
      "\n",
      "Train perplexity: 37303.7\n",
      "Train accuracy: 0.00357144\n",
      "Train discriminator accuracy: 95.9597\n",
      "Validation perplexity: 35529.1\n",
      "Validation accuracy: 0.00312198\n",
      "Validation discriminator accuracy: 86.9802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.data.uniform_(-opt.param_init, opt.param_init)\n",
    "\n",
    "encoder.load_pretrained_vectors(opt)\n",
    "decoder.load_pretrained_vectors(opt)\n",
    "\n",
    "optim = onmt.Optim(\n",
    "    opt.optim, opt.learning_rate, opt.max_grad_norm,\n",
    "    lr_decay=opt.learning_rate_decay,\n",
    "    start_decay_at=opt.start_decay_at\n",
    ")\n",
    "\n",
    "# optim = optimizer.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "optim.set_parameters(model.parameters())\n",
    "\n",
    "nParams = sum([p.nelement() for p in model.parameters()])\n",
    "print('* number of parameters: %d' % nParams)\n",
    "\n",
    "trainModel(model, trainData, validData, domain_train, domain_valid, dataset, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
